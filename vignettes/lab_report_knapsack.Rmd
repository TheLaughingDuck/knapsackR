---
title: "Knapsack lab report"
author: "Simon Jorstedt & Muditha Cherangani"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{knapsackR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## The knapsack problem
The knapsack problem is a combinatorial problem that involves creating a selection of some given objects with associated weight and value in such a way that their combined weigtht does not exceed a given limit, and their combined value is maximised. In this package we will only consider the 0-1 knapsack problem variation, where each object can either be selected *once* or *not at all*.

To get started, we will load the package in the chunk below.

```{r setup}
library(knapsackR)
```

For our examples below we will be using the following simulated objects.

```{r RandomdataChunk}
RNGversion(min(as.character(getRversion()),"3.5.3"))

##old sampler used for backward compatibility
## suppressWarnings() can be used so that the above warning is not displayed
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 10**6
knapsack_objects <-
data.frame(
w=sample(1:4000, size = n, replace = TRUE),
v=runif(n = n, 0, 10000)
)
```

## The `knapsack_brute_force` function
The first method we will discuss is the **Brute force method**, which calculates the combined weights and values of all possible combinations. The combination of objects with the highest value that still respects the weight limit is guaranteed to be the optimal solution. Below, we run an implementation of the brute force algorithm on a dataframe with 16 objects. The computation time and result of the algorithm is returned.


## Question-1

> How much time does it takes to run the brute force algorithm for n = 16 objects?

In the chunk below, we see that it takes the algorithm less than 1 second to solve the knapsack problem with $n=16$ objects. Additionaly, we see that there is an time improvement when the parallelized algorithm is used. This improvement would likely be more evident when the algorithm is run on a larger selection of objects.

```{r BruteForceChunk}
# Regular brute force implementation
system.time(results <- brute_force_knapsack(knapsack_objects[1:16,], 3500))
results

# Parallelized brute force implementation
system.time(results <- brute_force_knapsack(knapsack_objects[1:16,], 3500, parallel = TRUE))
results
```

## Dynamic programming
Another approach to solving the knapsack problem is through **dynamic programming** (see pseudocode on the [knapsack wikipedia page](https://en.wikipedia.org/wiki/Knapsack_problem#0-1_knapsack_problem)). Below, we run an implementation of the dynamic approach described above on a dataframe with 500 objects. The computation time and result of the algorithm is returned.

## Question-2

> How much time does it takes to run the dynamic algorithm for n = 500 objects?

```{r DynamicChunk}
# Dynamic implementation

system.time(results <- dynamic_knapsack(knapsack_objects[1:500,], 3500))

results
```


## Greedy heuristic
Another method for solving the knapsack problem is a (heuristic) **greedy** approach (see pseudocode on the [knapsack wikipedia page](https://en.wikipedia.org/wiki/Knapsack_problem#Greedy_approximation_algorithm)). Below, we run an implementation of the dynamic approach described above on a dataframe with `10^6` objects. The computation time and result of the algorithm is returned.

## Question-3

> How much time does it takes to run the greedy heuristic algorithm for n = 1000000 objects?

```{r Greedychunk}
# Greedy Heuristic implementation

system.time(results <- greedy_knapsack(knapsack_objects[1:10**6,], 100))

results
```


## Question-4

> What performance gain could you get by trying to improving your code?

The overall time taken to run an algorithm could be lowered. In some cases, a better solution could be achieved.

## Question-5

> What performance gain could you get by parallelizing brute force search?

By parallelizing the brute force implementation across multiple cores, we could achieve a speedup roughly proportional to the number of cores used. In other words, a reduced execution time.

